{"uid":"815e6629d0a62693","name":"Validate Council Output [SouthOxfordshireCouncil-None-None]","fullName":"features/validate_council_outputs.feature:Validate Council Output","historyId":"7f57931d644fea4dd7a0419f9995c47e","time":{"start":1705022110632,"stop":1705022114375,"duration":3743},"status":"failed","statusMessage":"ValueError: Error parsing bin data: list index out of range","statusTrace":"self = <SouthOxfordshireCouncil.CouncilClass object at 0x7f737d018a90>\npage = ''\nkwargs = {'headless': True, 'paon': None, 'postcode': None, 'uprn': '10033002851', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...e?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=420435299\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = list(bin.stripped_strings)\n            try:\n                # On standard collection schedule, date will be contained in the first stripped string\n                if contains_date(bin_info[0]):\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[0] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[1])\n                # On exceptional collection schedule (e.g. around English Bank Holidays), date will be contained in the second stripped string\n                else:\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n>                           bin_info[1] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\nE                   IndexError: list index out of range\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:74: IndexError\n\nDuring handling of the above exception, another exception occurred:\n\nfixturefunc = <function scrape_step at 0x7f738eb736d0>\nrequest = <FixtureRequest for <Function test_scenario_outline[SouthOxfordshireCouncil-None-None]>>\nkwargs = {'context': <test_validate_council.context.<locals>.Context object at 0x7f737c0d5c90>, 'council': 'SouthOxfordshireCouncil', 'selenium_mode': 'None', 'selenium_url': 'None'}\n\n    def call_fixture_func(\n        fixturefunc: \"_FixtureFunc[FixtureValue]\", request: FixtureRequest, kwargs\n    ) -> FixtureValue:\n        if is_generator(fixturefunc):\n            fixturefunc = cast(\n                Callable[..., Generator[FixtureValue, None, None]], fixturefunc\n            )\n            generator = fixturefunc(**kwargs)\n            try:\n                fixture_result = next(generator)\n            except StopIteration:\n                raise ValueError(f\"{request.fixturename} did not yield a value\") from None\n            finalizer = functools.partial(_teardown_yield_fixture, fixturefunc, generator)\n            request.addfinalizer(finalizer)\n        else:\n            fixturefunc = cast(Callable[..., FixtureValue], fixturefunc)\n>           fixture_result = fixturefunc(**kwargs)\n\n../../../.cache/pypoetry/virtualenvs/uk-bin-collection-EwS6Gn8s-py3.10/lib/python3.10/site-packages/_pytest/fixtures.py:902: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nuk_bin_collection/tests/step_defs/test_validate_council.py:92: in scrape_step\n    context.parse_result = CollectData.run()\nuk_bin_collection/uk_bin_collection/collect_data.py:96: in run\n    return self.client_code(\nuk_bin_collection/uk_bin_collection/collect_data.py:115: in client_code\n    return get_bin_data_class.template_method(address_url, **kwargs)\nuk_bin_collection/uk_bin_collection/get_bin_data.py:78: in template_method\n    bin_data_dict = self.parse_data(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <SouthOxfordshireCouncil.CouncilClass object at 0x7f737d018a90>\npage = ''\nkwargs = {'headless': True, 'paon': None, 'postcode': None, 'uprn': '10033002851', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...e?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=420435299\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = list(bin.stripped_strings)\n            try:\n                # On standard collection schedule, date will be contained in the first stripped string\n                if contains_date(bin_info[0]):\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[0] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[1])\n                # On exceptional collection schedule (e.g. around English Bank Holidays), date will be contained in the second stripped string\n                else:\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[1] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[2])\n            except Exception as ex:\n>               raise ValueError(f\"Error parsing bin data: {ex}\")\nE               ValueError: Error parsing bin data: list index out of range\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:80: ValueError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[],"testStage":{"status":"failed","statusMessage":"ValueError: Error parsing bin data: list index out of range","statusTrace":"self = <SouthOxfordshireCouncil.CouncilClass object at 0x7f737d018a90>\npage = ''\nkwargs = {'headless': True, 'paon': None, 'postcode': None, 'uprn': '10033002851', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...e?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=420435299\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = list(bin.stripped_strings)\n            try:\n                # On standard collection schedule, date will be contained in the first stripped string\n                if contains_date(bin_info[0]):\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[0] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[1])\n                # On exceptional collection schedule (e.g. around English Bank Holidays), date will be contained in the second stripped string\n                else:\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n>                           bin_info[1] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\nE                   IndexError: list index out of range\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:74: IndexError\n\nDuring handling of the above exception, another exception occurred:\n\nfixturefunc = <function scrape_step at 0x7f738eb736d0>\nrequest = <FixtureRequest for <Function test_scenario_outline[SouthOxfordshireCouncil-None-None]>>\nkwargs = {'context': <test_validate_council.context.<locals>.Context object at 0x7f737c0d5c90>, 'council': 'SouthOxfordshireCouncil', 'selenium_mode': 'None', 'selenium_url': 'None'}\n\n    def call_fixture_func(\n        fixturefunc: \"_FixtureFunc[FixtureValue]\", request: FixtureRequest, kwargs\n    ) -> FixtureValue:\n        if is_generator(fixturefunc):\n            fixturefunc = cast(\n                Callable[..., Generator[FixtureValue, None, None]], fixturefunc\n            )\n            generator = fixturefunc(**kwargs)\n            try:\n                fixture_result = next(generator)\n            except StopIteration:\n                raise ValueError(f\"{request.fixturename} did not yield a value\") from None\n            finalizer = functools.partial(_teardown_yield_fixture, fixturefunc, generator)\n            request.addfinalizer(finalizer)\n        else:\n            fixturefunc = cast(Callable[..., FixtureValue], fixturefunc)\n>           fixture_result = fixturefunc(**kwargs)\n\n../../../.cache/pypoetry/virtualenvs/uk-bin-collection-EwS6Gn8s-py3.10/lib/python3.10/site-packages/_pytest/fixtures.py:902: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nuk_bin_collection/tests/step_defs/test_validate_council.py:92: in scrape_step\n    context.parse_result = CollectData.run()\nuk_bin_collection/uk_bin_collection/collect_data.py:96: in run\n    return self.client_code(\nuk_bin_collection/uk_bin_collection/collect_data.py:115: in client_code\n    return get_bin_data_class.template_method(address_url, **kwargs)\nuk_bin_collection/uk_bin_collection/get_bin_data.py:78: in template_method\n    bin_data_dict = self.parse_data(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <SouthOxfordshireCouncil.CouncilClass object at 0x7f737d018a90>\npage = ''\nkwargs = {'headless': True, 'paon': None, 'postcode': None, 'uprn': '10033002851', ...}\nuser_uprn = '10033002851', cookies = {'SVBINZONE': 'SOUTH%3AUPRN%4010033002851'}\nheaders = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8', 'Accept-Language': 'en-GB,en;q=0.7', 'Cache-Control': 'max-age=0', 'Connection': 'keep-alive', ...}\nparams = {'SOVA_TAG': 'SOUTH', 'ebd': '0'}, response = <Response [200]>\nsoup = <!DOCTYPE html>\n\n<html lang=\"EN\">\n<!-- \n Powered by Verj.io\n www.verj.io\n -->\n<head>\n<meta content=\"text/html; charset...e?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&amp;ns=2&amp;cb=420435299\" type=\"text/javascript\"></script></body>\n</html>\n\ndata = {'bins': []}\n\n    def parse_data(self, page: str, **kwargs) -> dict:\n        user_uprn = kwargs.get(\"uprn\")\n        check_uprn(user_uprn)\n    \n        # UPRN is passed in via a cookie. Set cookies/params and GET the page\n        cookies = {\n            # 'JSESSIONID': '96F2A15C14569B2ED2BBEB140FE86532',\n            \"SVBINZONE\": f\"SOUTH%3AUPRN%40{user_uprn}\",\n        }\n        headers = {\n            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n            \"Accept-Language\": \"en-GB,en;q=0.7\",\n            \"Cache-Control\": \"max-age=0\",\n            \"Connection\": \"keep-alive\",\n            \"Referer\": \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb?SOVA_TAG=SOUTH&ebd=0&ebz=1_1668467255368\",\n            \"Sec-Fetch-Dest\": \"document\",\n            \"Sec-Fetch-Mode\": \"navigate\",\n            \"Sec-Fetch-Site\": \"same-origin\",\n            \"Sec-Fetch-User\": \"?1\",\n            \"Sec-GPC\": \"1\",\n            \"Upgrade-Insecure-Requests\": \"1\",\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\",\n        }\n        params = {\n            \"SOVA_TAG\": \"SOUTH\",\n            \"ebd\": \"0\",\n            # 'ebz':      '1_1668467255368',\n        }\n        requests.packages.urllib3.disable_warnings()\n        response = requests.get(\n            \"https://eform.southoxon.gov.uk/ebase/BINZONE_DESKTOP.eb\",\n            params=params,\n            headers=headers,\n            cookies=cookies,\n        )\n    \n        # Parse response text for super speedy finding\n        soup = BeautifulSoup(response.text, features=\"html.parser\")\n        soup.prettify()\n    \n        data = {\"bins\": []}\n    \n        # Page has slider info side by side, which are two instances of this class\n        for bin in soup.find_all(\"div\", {\"class\": \"binextra\"}):\n            bin_info = list(bin.stripped_strings)\n            try:\n                # On standard collection schedule, date will be contained in the first stripped string\n                if contains_date(bin_info[0]):\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[0] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[1])\n                # On exceptional collection schedule (e.g. around English Bank Holidays), date will be contained in the second stripped string\n                else:\n                    bin_date = get_next_occurrence_from_day_month(\n                        datetime.strptime(\n                            bin_info[1] + \" \" + datetime.today().strftime(\"%Y\"),\n                            \"%A %d %B - %Y\",\n                        )\n                    ).strftime(date_format)\n                    bin_type = str.capitalize(bin_info[2])\n            except Exception as ex:\n>               raise ValueError(f\"Error parsing bin data: {ex}\")\nE               ValueError: Error parsing bin data: list index out of range\n\nuk_bin_collection/uk_bin_collection/councils/SouthOxfordshireCouncil.py:80: ValueError","steps":[{"name":"Given the council: SouthOxfordshireCouncil","time":{"start":1705022110632,"stop":1705022110632,"duration":0},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"When we scrape the data from SouthOxfordshireCouncil using None and the None is set","time":{"start":1705022110633,"stop":1705022114375,"duration":3742},"status":"failed","statusMessage":"Error parsing bin data: list index out of range","statusTrace":"ValueError: Error parsing bin data: list index out of range\n","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":true,"stepsCount":0,"attachmentsCount":0,"hasContent":true,"attachmentStep":false}],"attachments":[],"parameters":[],"shouldDisplayMessage":true,"stepsCount":2,"attachmentsCount":0,"hasContent":true,"attachmentStep":false},"afterStages":[],"labels":[{"name":"host","value":"fv-az661-721"},{"name":"thread","value":"2770-MainThread"},{"name":"framework","value":"pytest-bdd"},{"name":"language","value":"cpython3"},{"name":"feature","value":"Test each council output matches expected results"},{"name":"resultFormat","value":"allure2"}],"parameters":[{"name":"council","value":"SouthOxfordshireCouncil"},{"name":"selenium_mode","value":"None"},{"name":"selenium_url","value":"None"}],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"Product defects","matchedStatuses":[],"flaky":false}],"tags":[]},"source":"815e6629d0a62693.json","parameterValues":["SouthOxfordshireCouncil","None","None"]}